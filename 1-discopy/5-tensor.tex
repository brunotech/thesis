%!TEX root = ms.tex

Let $\mathbf{Mat}_\bb{S}$ be the category with objects the natural numbers and arrows $m \to n$ the matrices $[n] \times [m] \to \bb{S}$ for a commutative semiring $\bb{S}$, with Kronecker product as tensor.
$\mathbf{Mat}_\bb{S}$ is compact closed, i.e. both symmetric monoidal and rigid. It is furthermore self-dual, i.e. objects are isomorphic to their adjoints.
For $\bb{S} = \bb{B}$, we get a category equivalent to finite sets and relations with Cartesian product.
For $\bb{S} = \bb{C}$, it is equivalent to finite-dimensional complex vector spaces and linear maps with the usual tensor product.
In practice, it is more convenient to consider an equivalent category $\mathbf{Tensor}_\bb{S}$ where objects are lists of natural numbers and adjoints are given by list reversal.
Arrows $(m_1, \dots, m_k) \to (n_1, \dots, n_{k'})$ are tensors of order $k + k'$, i.e. matrices $m_1 \times \dots \times m_k \to n_1 \times \dots \times n_{k'}$.

\begin{class}\normalfont\texttt{Dim(n\_0, ..., n\_k)}
is a subclass of \py{rigid.Ty} generated by natural numbers.
\end{class}

\begin{class}\normalfont\texttt{Tensor(dom, cod, array)}
is a subclass of \py{rigid.Box} given by \py{Dim}-instances \py{dom} and \py{cod} and a \texttt{numpy} \cite{VanderWaltEtAl11} \py{array} of the appropriate shape.
\py{then} and \py{tensor} are both implemented using \py{numpy.tensordot}, \py{cups} and \py{caps} return a reshaped identity.
\end{class}

\begin{class}\normalfont\texttt{TensorFunctor(ob, ar)}
is a subclass of \py{rigid.Functor} where \py{ob} and \py{ar} are mappings from \py{Ty} to \py{Dim} and from \py{Box} to \py{Tensor} respectively.
\end{class}

\begin{remark}
All the methods of the \py{Tensor} class are writen in \normalfont{\texttt{jax.numpy}}, the subset of Python+\normalfont{\texttt{numpy}} that supports automatic differentiation with \normalfont{\texttt{jax}} \cite{Google/jax20}.
\end{remark}

\begin{example}
Tensor networks can be defined as diagrams with a functor into tensors, contraction is given by functor application. They have been applied to both condensed matter physics and machine learning, see \cite{Orus14} for an introduction.
Interfacing \normalfont{DisCoPy} with tensor network tools such as \cite{KossaifiEtAl18,HauschildPollmann18,RobertsEtAl19} is left for future work.
\end{example}

\begin{example}
Relational databases can be defined as Boolean tensors: a table with $k$ columns is a state $1 \to (n_1, \dots, n_k)$ in $\mathbf{Tensor}_\bb{B}$.
Conjunctive queries are diagrams, where query containment gives the structure of a free Cartesian bicategory, see \cite{BonchiEtAl18}.
Query evaluation over a relational database is the application a functor into Boolean tensors.
\end{example}

\begin{example}\label{example-discocat}
The distributional compositional (DisCo) models of Coecke et al.
\cite{ClarkEtAl08,ClarkEtAl10} can be defined as functors
$F : \mathbf{G} \to \mathbf{Tensor}_\bb{S}$ from the rigid category $\mathbf{G}$ generated by
a pregroup grammar (see example~\ref{example-pregroup}) into tensors, i.e. they map pregroup types $t \in \mathbf{G}$ to dimensions $F(t) \in \bb{N}^\star$ and dictionnary entries $w \to t$ to tensors of shape $F(t)$.
When $F(s) = 1$, the meaning for a grammatical sentence $g : w_1 \dots w_n \to s$ is a scalar $F(g) \in \bb{S}$ which can be computed as the contraction of a tensor network.
DisCo models into real vector spaces, i.e. with $\bb{S} = \bb{R}$, received experimental support, see \cite{GrefenstetteSadrzadeh11,KartsaklisEtAl12,KartsaklisEtAl13}.
Relational DisCo models, i.e. with $\bb{S} = \bb{B}$, have been applied to question answering, see \cite{CoeckeEtAl18a, DeFeliceEtAl19a}.
\end{example}
